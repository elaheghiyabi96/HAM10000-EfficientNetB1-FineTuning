# HAM10000-EfficientNetB1-FineTuning
Skin lesion classification on the HAM10000 dataset using EfficientNetB1 with transfer learning and fine-tuning. The model applies data augmentation, class weighting, and staged unfreezing to handle class imbalance and improve validation performance across 7 lesion categories.
This work presents the eighth model in our experimental pipeline for skin lesion classification on the HAM10000 dataset, based on EfficientNetB1 with transfer learning and fine-tuning. The primary objective of this model was to improve classification performance while maintaining a favorable balance between accuracy, model complexity, and training stability. Compared to earlier models—such as custom CNN architectures and heavier transfer-learning backbones explored previously—EfficientNetB1 offers a more principled compound scaling strategy that jointly optimizes network depth, width, and input resolution, making it particularly well suited for medical image analysis with limited and imbalanced data.

The HAM10000 dataset consists of dermoscopic images categorized into seven diagnostic classes. The data were split into training and validation sets using stratified sampling to preserve class distributions, resulting in 8012 training images and 2003 validation images. All images were resized to 224×224 pixels and processed using the official EfficientNet preprocessing function. To improve generalization and reduce overfitting, an extensive data augmentation pipeline was applied, including random horizontal and vertical flipping, rotation, zooming, brightness adjustment, and contrast variation. This augmentation strategy was more aggressive than in some earlier models and played a key role in stabilizing training, particularly for minority classes.

A major challenge of the HAM10000 dataset is severe class imbalance, with the melanocytic nevi (nv) class dominating the sample distribution. To address this issue, class weights were computed using a balanced weighting scheme and incorporated directly into the loss function during training. This approach provided a measurable improvement over earlier baseline CNN models that did not explicitly handle imbalance and showed more stable learning behavior compared to some previous transfer-learning experiments without class reweighting.

In the first training phase, EfficientNetB1 was used as a frozen feature extractor pretrained on ImageNet, with only a lightweight classification head trained on top. This head consisted of global average pooling, dropout, and a fully connected softmax layer. In this feature-extraction phase, the model converged rapidly and achieved a validation accuracy of 68.10%. This performance already exceeded that of earlier custom CNN architectures and was competitive with previously tested pretrained models, while using fewer trainable parameters and exhibiting smoother convergence.

To further enhance performance, a second phase of fine-tuning was conducted by unfreezing the top 30 layers of the EfficientNetB1 backbone and retraining the network with a very low learning rate. This allowed the model to adapt high-level visual features to domain-specific characteristics of dermoscopic images, such as lesion borders, color variation, and texture patterns. Fine-tuning resulted in a clear and consistent performance gain, raising the validation accuracy to 71.89%. Compared to earlier models, this improvement was achieved with better training stability and without signs of severe overfitting.

A detailed analysis of the classification report shows that the model performs particularly well on the dominant nv class, while also improving precision for several minority classes such as basal cell carcinoma and vascular lesions. However, recall for extremely underrepresented classes (e.g., dermatofibroma and actinic keratoses) remains limited, indicating that data imbalance continues to constrain macro-averaged performance. This limitation was also observed in previous models, suggesting that architectural improvements alone may not be sufficient and that future work should consider advanced imbalance-handling strategies such as focal loss, oversampling, or hybrid multimodal approaches.

Overall, EfficientNetB1 with fine-tuning represents one of the strongest baselines evaluated so far in this project. Compared to earlier custom CNNs, it delivers substantially higher accuracy and better generalization. Compared to previously tested transfer-learning models, it achieves a more favorable trade-off between performance and model efficiency. As such, it provides a solid foundation for further experimentation, including attention mechanisms, ensemble learning, or clinical feature integration.

The HAM10000 dataset used in this study is publicly available at:
https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000
